{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results from Airtable ##\n",
    "\n",
    "### Objective ###\n",
    "\n",
    "By analyzing the result from OpenAlpr API (API), this aims to extract patterns in data that will aid to construct methodoloy(ies) to classify frames into 2 categories.\n",
    "1. contains license plate of entry vehicle, and is clearly visible, and will get response from API \n",
    "2. Does not contain license plate at all; contains irrelevant license plate/vehicle. \n",
    "\n",
    "Here, we will only focus on the first 2 criterias of the first category above. Even if a frame contains license plate of entry vehicle and it is clearly visible, that does not garuntee successful response from the API due to other factor such as lightning or focus of the video, which are out of scope for this investiagation.\n",
    "\n",
    "analyzing uploaded result on airtable to extract patterns among frames that got plate info back from openalpr.\n",
    "\n",
    "### Data ###\n",
    "Data was gained by processing 6hrs long video from Safie stream using the following methods.\n",
    "1. Motion sensing with openCV backgroundSubstractor\n",
    "2. MobileNet SSD\n",
    "\n",
    "Out of all frames, ones that contains \"car\" label, which overlaps with pre-defined area of interest (AoI) were selected, and sent to OpenAlpr API (API).\n",
    "The data include the result from the API, as well as metadeta from object detection, time etc.\n",
    "\n",
    "Data is **labeled by hand** in binary fashion. Data that meets the following criterias are labeled as _positive_\n",
    "1. MobileNet SSD is detecting objects correctly (no weird bounding box)\n",
    "2. license plate of entry vehicles (to the gate) is clearly visible in the frame\n",
    "\n",
    "Wether or not a plate was detected by the API was used as label before, but it is not appropriate and not aligned with the objective of this project, as it also included detection such as followings.\n",
    "1. license plate that belongs to unrelevant vehicles (not entering to the gate)\n",
    "2. random signs or other objects recognized as license plate\n",
    "\n",
    "These seems to be the leading cause of low accuracy for previous analyzation.\n",
    "\n",
    "**Features**<br>\n",
    "Following features will be analyzed in this notebook.\n",
    "\n",
    "* **BoundingBox**: Bounding box of the detected car. Consists of the coordinates of the box, as well as area.\n",
    "* **Overlap**: overlapping area of bounding box and area of interest.\n",
    "\n",
    "Now data will be loaded and displayed.\n",
    "\n",
    "## Follow [this notebook](https://www.kaggle.com/kanncaa1/feature-selection-and-data-visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Unnamed: 0.1', 'カメラID', '物体画像', '処理開始時間', 'ナンバープレート',\n",
      "       'N地域名', 'N分類番号', 'N平仮名等', 'N一連指定番号', 'タイムスタンプ', '物体詳細', 'box_x_min',\n",
      "       'box_y_min', 'box_x_max', 'box_y_max', 'over_x_min', 'over_y_min',\n",
      "       'over_x_max', 'over_y_max', 'aoi_x_min', 'aoi_y_min', 'aoi_x_max',\n",
      "       'aoi_y_max', 'box_height', 'box_width', 'img_url', 'gate_incoming',\n",
      "       'box_area', 'overlap_area', 'area_of_interest', 'box_height_over_width',\n",
      "       'frame_area', 'plate_present', 'box_x_center', 'box_y_center',\n",
      "       'local_img_path', 'motion_score', 'blur_score', 'gate_plate',\n",
      "       'yolo_x_min', 'yolo_x_max', 'yolo_y_min', 'yolo_y_max', 'yolo_time'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>カメラID</th>\n",
       "      <th>物体画像</th>\n",
       "      <th>処理開始時間</th>\n",
       "      <th>ナンバープレート</th>\n",
       "      <th>N地域名</th>\n",
       "      <th>N分類番号</th>\n",
       "      <th>N平仮名等</th>\n",
       "      <th>N一連指定番号</th>\n",
       "      <th>...</th>\n",
       "      <th>box_y_center</th>\n",
       "      <th>local_img_path</th>\n",
       "      <th>motion_score</th>\n",
       "      <th>blur_score</th>\n",
       "      <th>gate_plate</th>\n",
       "      <th>yolo_x_min</th>\n",
       "      <th>yolo_x_max</th>\n",
       "      <th>yolo_y_min</th>\n",
       "      <th>yolo_y_max</th>\n",
       "      <th>yolo_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>401</td>\n",
       "      <td>401</td>\n",
       "      <td>entry_2021-02-16_09-01-00.mp4</td>\n",
       "      <td>camera_stored-video_car_247.jpg (https://dl.ai...</td>\n",
       "      <td>2021-02-20 02:09</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275</td>\n",
       "      <td>/home/wataru/Projects/opencv_motion_detection/...</td>\n",
       "      <td>33300195.0</td>\n",
       "      <td>758.258661</td>\n",
       "      <td>0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>0.266696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>553</td>\n",
       "      <td>554</td>\n",
       "      <td>entry_2021-02-16_09-01-00.mp4</td>\n",
       "      <td>camera_stored-video_car_145.jpg (https://dl.ai...</td>\n",
       "      <td>2021-02-20 02:05</td>\n",
       "      <td>春日部 100 は 1978</td>\n",
       "      <td>春日部</td>\n",
       "      <td>100</td>\n",
       "      <td>は</td>\n",
       "      <td>1978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470</td>\n",
       "      <td>/home/wataru/Projects/opencv_motion_detection/...</td>\n",
       "      <td>41441835.0</td>\n",
       "      <td>967.198233</td>\n",
       "      <td>1</td>\n",
       "      <td>923.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.255055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>entry_2021-02-16_09-01-00.mp4</td>\n",
       "      <td>camera_stored-video_car_391.jpg (https://dl.ai...</td>\n",
       "      <td>2021-02-20 02:16</td>\n",
       "      <td>川崎 102 は ・・20</td>\n",
       "      <td>川崎</td>\n",
       "      <td>102</td>\n",
       "      <td>は</td>\n",
       "      <td>・・20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300</td>\n",
       "      <td>/home/wataru/Projects/opencv_motion_detection/...</td>\n",
       "      <td>34372980.0</td>\n",
       "      <td>608.770266</td>\n",
       "      <td>1</td>\n",
       "      <td>288.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>0.264710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>entry_2021-02-16_09-01-00.mp4</td>\n",
       "      <td>camera_stored-video_car_383.jpg (https://dl.ai...</td>\n",
       "      <td>2021-02-20 02:16</td>\n",
       "      <td>所沢 100 は ・・12</td>\n",
       "      <td>所沢</td>\n",
       "      <td>100</td>\n",
       "      <td>は</td>\n",
       "      <td>・・12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285</td>\n",
       "      <td>/home/wataru/Projects/opencv_motion_detection/...</td>\n",
       "      <td>43259220.0</td>\n",
       "      <td>748.140527</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>453</td>\n",
       "      <td>453</td>\n",
       "      <td>entry_2021-02-16_09-01-00.mp4</td>\n",
       "      <td>camera_stored-video_car_214.jpg (https://dl.ai...</td>\n",
       "      <td>2021-02-20 02:07</td>\n",
       "      <td>足立 800 か 2586</td>\n",
       "      <td>足立</td>\n",
       "      <td>800</td>\n",
       "      <td>か</td>\n",
       "      <td>2586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080</td>\n",
       "      <td>/home/wataru/Projects/opencv_motion_detection/...</td>\n",
       "      <td>45734760.0</td>\n",
       "      <td>584.099379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Unnamed: 0.1                          カメラID  \\\n",
       "401         401           401  entry_2021-02-16_09-01-00.mp4   \n",
       "553         553           554  entry_2021-02-16_09-01-00.mp4   \n",
       "205         205           205  entry_2021-02-16_09-01-00.mp4   \n",
       "213         213           213  entry_2021-02-16_09-01-00.mp4   \n",
       "453         453           453  entry_2021-02-16_09-01-00.mp4   \n",
       "\n",
       "                                                  物体画像            処理開始時間  \\\n",
       "401  camera_stored-video_car_247.jpg (https://dl.ai...  2021-02-20 02:09   \n",
       "553  camera_stored-video_car_145.jpg (https://dl.ai...  2021-02-20 02:05   \n",
       "205  camera_stored-video_car_391.jpg (https://dl.ai...  2021-02-20 02:16   \n",
       "213  camera_stored-video_car_383.jpg (https://dl.ai...  2021-02-20 02:16   \n",
       "453  camera_stored-video_car_214.jpg (https://dl.ai...  2021-02-20 02:07   \n",
       "\n",
       "           ナンバープレート N地域名 N分類番号 N平仮名等 N一連指定番号  ...  box_y_center  \\\n",
       "401            None  NaN   NaN   NaN    None  ...         0.275   \n",
       "553  春日部 100 は 1978  春日部   100     は    1978  ...         0.470   \n",
       "205   川崎 102 は ・・20   川崎   102     は    ・・20  ...         0.300   \n",
       "213   所沢 100 は ・・12   所沢   100     は    ・・12  ...         0.285   \n",
       "453   足立 800 か 2586   足立   800     か    2586  ...         0.080   \n",
       "\n",
       "                                        local_img_path  motion_score  \\\n",
       "401  /home/wataru/Projects/opencv_motion_detection/...    33300195.0   \n",
       "553  /home/wataru/Projects/opencv_motion_detection/...    41441835.0   \n",
       "205  /home/wataru/Projects/opencv_motion_detection/...    34372980.0   \n",
       "213  /home/wataru/Projects/opencv_motion_detection/...    43259220.0   \n",
       "453  /home/wataru/Projects/opencv_motion_detection/...    45734760.0   \n",
       "\n",
       "     blur_score  gate_plate  yolo_x_min  yolo_x_max  yolo_y_min  yolo_y_max  \\\n",
       "401  758.258661           0       232.0       326.0       311.0       367.0   \n",
       "553  967.198233           1       923.0      1039.0       499.0       577.0   \n",
       "205  608.770266           1       288.0       392.0       374.0       423.0   \n",
       "213  748.140527           1         0.0         0.0         0.0         0.0   \n",
       "453  584.099379           0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "     yolo_time  \n",
       "401   0.266696  \n",
       "553   0.255055  \n",
       "205   0.264710  \n",
       "213   0.263377  \n",
       "453   0.264097  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Given each frame's data and car, \n",
    "This will read and assign car numbers to frames, \n",
    "and visualize if wanted.\n",
    "'''\n",
    "import pandas as pd \n",
    "import cv2\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import webbrowser\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "def to_float(lp):\n",
    "    try:\n",
    "        return float(lp)\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "def to_bool(num):\n",
    "    return True if num == 1 else False\n",
    "\n",
    "def to_link(string):\n",
    "    '''\n",
    "    given url string, return it in a tag\n",
    "    '''\n",
    "    fstring = '<a href={url}>img link</a>'.format(url=string)\n",
    "    return fstring\n",
    "\n",
    "def url_to_local_img(img_url, img_dir_path):\n",
    "    '''convert url string into local image path'''\n",
    "    img_file_name = img_url.split(\"?\")[0].split('/')[-1]\n",
    "    return os.path.join(img_dir_path, img_file_name)\n",
    "\n",
    "#file = 'adjusted_video_box3.csv'\n",
    "file = 'entry_2_16_9_yolo_hand_labeled.csv'\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "print(df.columns)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there are lots of unrelated columns present in the dataframe. Let's pick the columns that are \n",
    "relevant for this analysis.\n",
    "\n",
    "Label is `get_plate` column, which shows weather the license plate of entry vehicle is present in the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ナンバープレート\"] = df[\"ナンバープレート\"].str.strip()\n",
    "\n",
    "\n",
    "columns = ['処理開始時間', 'ナンバープレート','タイムスタンプ','box_x_min',\n",
    "       'box_y_min', 'box_x_max', 'box_y_max', 'over_x_min', 'over_y_min',\n",
    "       'over_x_max', 'over_y_max', 'aoi_x_min', 'aoi_y_min', 'aoi_x_max',\n",
    "       'aoi_y_max', 'box_height', 'box_width', 'img_url', 'gate_incoming',\n",
    "       'box_area', 'overlap_area', 'area_of_interest', 'box_height_over_width',\n",
    "       'frame_area', 'plate_present', 'box_x_center', 'box_y_center',\n",
    "       'local_img_path', 'motion_score', 'blur_score', 'gate_plate',\n",
    "       'yolo_x_min', 'yolo_x_max', 'yolo_y_min', 'yolo_y_max', 'yolo_time']\n",
    "\n",
    "yolo_columns = ['物体画像', 'ナンバープレート','box_x_min', 'box_y_min', 'box_x_max', 'box_y_max', 'over_x_min', 'over_y_min', \\\n",
    "         'over_x_max', 'over_y_max', 'aoi_x_min', 'aoi_y_min', 'aoi_x_max', 'aoi_y_max', 'box_height', 'box_width', \\\n",
    "        'yolo_x_min', 'yolo_x_max', 'yolo_y_min', 'yolo_y_max','yolo_time', \"img_url\", \"local_img_path\"]\n",
    "\n",
    "\n",
    "## select columns that are relevant to data analysis purpose\n",
    "df = df[columns]\n",
    "#df.drop_duplicates(subset=['img_url'], inplace=True, keep=False)\n",
    "'''\n",
    "df['box_area'] = (df['box_x_max'] - df['box_x_min'])*(df['box_y_max'] - df['box_y_min'])\n",
    "df['overlap_area'] = (df['over_x_max'] - df['over_x_min'])*(df['over_y_max'] - df['over_y_min'])\n",
    "df['area_of_interest'] = (df['aoi_x_max'] - df['aoi_x_min'])*(df['aoi_y_max'] - df['aoi_y_min'])\n",
    "df['box_height_over_width'] = df['box_height'] / df['box_width']\n",
    "# checking this\n",
    "#df['overlap_right_buttom'] = df[(df['box_x_min'] < df['aoi_x_min']) & (df['aoi_x_min'] < df['aoi_x_max'])]\n",
    "df['frame_area'] = 1\n",
    "df.loc[df[\"ナンバープレート\"] != \"None\", 'plate_present'] = 1\n",
    "df.loc[df[\"ナンバープレート\"] == \"None\", 'plate_present'] = 0\n",
    "\n",
    "\n",
    "df['box_x_center'] = (df['box_x_min']+df['box_x_max'])/2\n",
    "df['box_y_center'] = (df['box_y_min']+df['box_y_max'])/2\n",
    "\n",
    "local_img_path = 'trucks'\n",
    "df['local_img_path'] = df['img_url'].map(lambda x: url_to_local_img(x, local_img_path))\n",
    "print(df['local_img_path'])\n",
    "df['motion_score'] = ''\n",
    "df['blur_score'] = ''\n",
    "\n",
    "for ind, row in df.iterrows():\n",
    "    dic = json.loads(row['物体詳細'])\n",
    "    for k, v in dic.items():\n",
    "        df.loc[ind, k] = v\n",
    "\n",
    "# drop value where gate_incoming == ?\n",
    "print(df['gate_incoming'].value_counts())\n",
    "df = df[df['gate_incoming'] != \"?\"]\n",
    "df = df[df['gate_incoming'] != \"-\"]\n",
    "\n",
    "df['gate_incoming'] = df['gate_incoming'].astype(float)\n",
    "\n",
    "df['gate_plate'] = 0\n",
    "df.loc[(df['plate_present'] == 1) & (df['gate_incoming'] ==1 ), 'gate_plate'] = 1\n",
    "\n",
    "df.to_csv(\"hand_labeled_table.csv\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Evaluation & Selection ###\n",
    "\n",
    "Because there are fair numbers of columns (features) available in the dataset, I have applied feature selection methods to see how much each feature is correlated to the label.\n",
    "\n",
    "There are [several feature selection methods](https://machinelearningmastery.com/feature-selection-machine-learning-python/), but I will use _Univariate Selection Method_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['over_x_min', 'over_y_min', 'over_x_max', 'over_y_max', 'overlap_area']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "box_height               65.179622\n",
       "box_height_over_width    45.158827\n",
       "box_y_max                44.734900\n",
       "box_y_min                32.974030\n",
       "box_y_center             27.050786\n",
       "blur_score               20.075598\n",
       "aoi_y_min                13.781818\n",
       "motion_score             10.277197\n",
       "area_of_interest          8.239130\n",
       "box_x_min                 1.912947\n",
       "box_width                 0.517836\n",
       "box_x_center              0.289127\n",
       "box_area                  0.229229\n",
       "box_x_max                 0.000123\n",
       "aoi_y_max                 0.000000\n",
       "aoi_x_max                 0.000000\n",
       "aoi_x_min                -3.697561\n",
       "dtype: float64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "feature_cols = ['box_x_min','box_y_min', 'box_x_max', 'box_y_max', 'over_x_min', 'over_y_min',\n",
    "                'over_x_max', 'over_y_max', 'aoi_x_min', 'aoi_y_min', 'aoi_x_max',\n",
    "                'aoi_y_max', 'box_height', 'box_width','box_area', 'overlap_area', \n",
    "                'area_of_interest', 'box_height_over_width','box_x_center', 'box_y_center', \n",
    "                'motion_score', 'blur_score']\n",
    "print([feature_cols[i] for i in [4,5,6, 7,15]])\n",
    "\n",
    "feature_cols = [feature_cols[i] for i in range(len(feature_cols)) if i not in [4,5,6, 7,15]]\n",
    "label_col = 'gate_incoming'\n",
    "\n",
    "data = df[feature_cols]\n",
    "label = df[label_col]\n",
    "\n",
    "X = data.values\n",
    "y = label.values\n",
    "\n",
    "def univariate(X, y):\n",
    "    '''Given x and y data, perform univariate analysis and return dictionary of features name and its scores'''\n",
    "    test = SelectKBest(score_func=f_classif, k=4)\n",
    "    fit = test.fit(X, y)\n",
    "    # summarize scores\n",
    "    set_printoptions(precision=3)\n",
    "    feature_score_dict = {k:v for k, v in zip(feature_cols, fit.scores_)}\n",
    "    feature_scores = dict(sorted(feature_score_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    # summarize scores\n",
    "    set_printoptions(precision=3)\n",
    "    return feature_scores\n",
    "\n",
    "# because of its nature, we'll run this couple times to take average score and decide which are \n",
    "# the most effective predictor\n",
    "feature_score_data = [univariate(X, y) for i in range(3)]\n",
    "fs_df = pd.DataFrame(feature_score_data, columns=feature_cols)\n",
    "fs_df.dropna(axis=1, how='all', inplace=True)\n",
    "fs_df.mean(axis=0).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     motion_score  blur_score\n",
      "0      20699370.0  282.295589\n",
      "1      24408345.0  519.447832\n",
      "2      20460180.0  235.039267\n",
      "3      19735725.0  419.717096\n",
      "4      19215780.0  287.335260\n",
      "..            ...         ...\n",
      "755    57875310.0  980.539293\n",
      "756    19639590.0  625.310960\n",
      "757    19472310.0  453.169682\n",
      "758    19472310.0  453.169682\n",
      "759    22713615.0  423.777975\n",
      "\n",
      "[760 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1880acea114a199a07cec6b8b39d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': array([1., 1., 1., ..., 0., 0., 0.])},\n",
       "              'mode': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graph?\n",
    "def do_click(trace, points, state):\n",
    "    if points.point_inds:\n",
    "        ind = points.point_inds[0]\n",
    "        url = df[\"img_url\"].iloc[ind]\n",
    "        webbrowser.open_new_tab(url)    \n",
    "\n",
    "#print(df[['box_area', 'area_of_interest', 'plate_present', 'yolo_x_min']])\n",
    "\n",
    "rg_x = df.loc[df['plate_present']==1, 'box_width'].values\n",
    "rg_y = df.loc[df['plate_present']==1, 'box_height'].values\n",
    "\n",
    "rg_model = linear_model.LinearRegression()\n",
    "rg_model.fit(rg_x.reshape(-1,1), rg_y)\n",
    "pred = rg_model.predict(rg_x.reshape(-1, 1))\n",
    "\n",
    "print(df[['motion_score', 'blur_score']])\n",
    "fig = go.FigureWidget(layout={'hovermode': 'closest', \"title_text\":\"box's width and height\"})\n",
    "#_ = fig.add_scatter(x=df['box_height_over_width'], y=df['plate_present'], mode='markers', marker={\"color\":df['plate_present']})\n",
    "_ = fig.add_scatter(x=df['box_width'], y=df['box_height'], mode='markers', marker={\"color\":df['gate_incoming'].astype(float)})\n",
    "_ = fig.add_scatter(x=rg_x, y=pred, mode='lines')\n",
    "scatter = fig.data[0]\n",
    "scatter.on_click(do_click)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Analysis\n",
    "\n",
    "A major cluster is observable in the center, spreading from buttom left to top right, making increasing regression pattern with some spreads in y axis.\n",
    "Also some following rules.\n",
    "\n",
    "* exclude `box_width` <= 0.25 & `box_height` <= 0.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4def306ede4f5ea55461f7f8e8a088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': array(['rgb(0,0,255)', 'rgb(0,0,255)', 'rgb(255,0,0)', ..., '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def do_click(trace, points, state):\n",
    "    if points.point_inds:\n",
    "        ind = points.point_inds[0]\n",
    "        url = df[\"img_url\"].iloc[ind]\n",
    "        webbrowser.open_new_tab(url)\n",
    "\n",
    "colorsIdx = {1.0: 'rgb(255,0,0)', 0.0: 'rgb(0,0,255)'}\n",
    "cols   = df['gate_plate'].map(colorsIdx)\n",
    "\n",
    "fig = go.FigureWidget(layout={'hovermode': 'closest', \"title_text\":\"BoundingBox's Width vs Height\"})\n",
    "#_ = fig.add_scatter(x=df['box_x_center'], y=df['box_y_center'], mode='markers', marker={\"color\":cols})\n",
    "_ = fig.add_scatter3d(x=df['box_x_center'], y=df['box_y_center'], z=df['blur_score'], mode='markers', marker={\"color\":cols})\n",
    "#_ = fig.add_scatter3d(x=df['box_x_center'],y=df['box_y_center'], z=df['box_area'], mode='markers', marker={\"color\":df['plate_present']})\n",
    "fig.update_layout(\n",
    "width=800,\n",
    "height=800)\n",
    "scatter = fig.data[0]\n",
    "scatter.on_click(do_click)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Analysis\n",
    "\n",
    "### Cluster of non-plate at top\n",
    "* vehicle going in, with obj area filling up the frame. Almost sideways. => `box_area` > 0.9\n",
    "\n",
    "* vehicle going in is focused around (0.3, 0.3) forming circule. use kerenel??\n",
    "\n",
    "Based on the analyses above, will plot the graph again after applying the rules to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 31) (338, 31)\n",
      "(202, 31)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183c9aa5c5fb4b76a152db37c9ec543a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': array([0., 0., 1., ..., 0., 0., 0.])},\n",
       "              'mode': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pf = df.loc[((df['box_area'] > 0.1) & (df['box_area'] < 0.9)) & ((df['box_width'] > 0.25) | (df['box_height'] > 0.3)) & (df['box_x_center'] > 0.15)]\n",
    "print(df[df['plate_present']==1].shape, pf.shape)\n",
    "print(pf[pf['plate_present'] == 1].shape)\n",
    "\n",
    "def do_click(trace, points, state):\n",
    "    if points.point_inds:\n",
    "        ind = points.point_inds[0]\n",
    "        url = pf[\"img_url\"].iloc[ind]\n",
    "        webbrowser.open_new_tab(url)\n",
    "\n",
    "fig = go.FigureWidget(layout={'hovermode': 'closest', \"title_text\":\"box's center coordinate vs plate_present\"})\n",
    "#_ = fig.add_scatter(x=df['box_x_center'], y=df['box_y_center'], mode='markers', marker={\"color\":df['plate_present']})\n",
    "_ = fig.add_scatter3d(x=pf['box_x_center'],y=pf['box_y_center'], z=pf['box_area'], mode='markers', marker={\"color\":pf['plate_present']})\n",
    "scatter = fig.data[0]\n",
    "scatter.on_click(do_click)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 31)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5887bc37a3b4e27841a2fd916ddc458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf = df[~df.index.isin(pf.index)]\n",
    "print(rf.shape)\n",
    "def do_click(trace, points, state):\n",
    "    if points.point_inds:\n",
    "        ind = points.point_inds[0]\n",
    "        url = rf[\"img_url\"].iloc[ind]\n",
    "        webbrowser.open_new_tab(url)\n",
    "\n",
    "fig = go.FigureWidget(layout={'hovermode': 'closest', \"title_text\":\"box's center coordinate vs plate_present\"})\n",
    "#_ = fig.add_scatter(x=df['box_x_center'], y=df['box_y_center'], mode='markers', marker={\"color\":df['plate_present']})\n",
    "_ = fig.add_scatter3d(x=rf['box_x_center'],y=rf['box_y_center'], z=rf['box_area'], mode='markers', marker={\"color\":rf['plate_present']})\n",
    "scatter = fig.data[0]\n",
    "scatter.on_click(do_click)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_image(FN, cols=6, rows=6, shrink=0.5, draw=False):\n",
    "    # int(FN.shape[0]/col)\n",
    "    i = 0\n",
    "    vstack = []\n",
    "    for row in range(rows):\n",
    "        hstack = []\n",
    "        for col in range(cols):\n",
    "            row_data = FN.loc[i]\n",
    "            image_path = os.path.join(*(row_data['local_img_path'].split('/')[-2:]))\n",
    "            image = cv2.imread(image_path)\n",
    "            # I just resized the image to a quarter of its original size\n",
    "            if draw:\n",
    "                start_point = (int(row_data['yolo_x_min']), int(row_data['yolo_y_min']))\n",
    "                end_point = (int(row_data['yolo_x_max']), int(row_data['yolo_y_max']))\n",
    "                color = (0, 0, 255)\n",
    "                thickness = 2\n",
    "                image = cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "            image = cv2.resize(image, (0, 0), None, shrink, shrink)\n",
    "            hstack.append(image)\n",
    "            i += 1\n",
    "        vstack.append(np.hstack(tuple(hstack)))\n",
    "    v_images = np.vstack(tuple(vstack))\n",
    "    cv2.imshow('Numpy Horizontal', v_images)\n",
    "    while True:\n",
    "        k = cv2.waitKey(0) & 0xFF\n",
    "        print(k)\n",
    "        if k == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "#rf = rf[rf['plate_present'] == 1].reset_index(drop=True)\n",
    "#pf = pf[pf['plate_present'] == 0] #.sample(36)\n",
    "##print(pf.shape)\n",
    "#tile_image(pf.reset_index(drop=True), cols=6, rows=6, shrink=0.5, draw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y, clf.predict(x))\n",
    "print(\"confusion matrix:\\n\", cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "\n",
    "recall = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "precision = cm[1][1]/(cm[0][1]+cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n",
      "0 (684, 392)\n",
      "1 (608, 338)\n",
      "2 (390, 180)\n",
      "3 (441, 212)\n",
      "11 (492, 223)\n",
      "14 (371, 194)\n",
      "15 (563, 251)\n",
      "16 (415, 251)\n",
      "17 (537, 540)\n",
      "18 (377, 201)\n",
      "19 (646, 273)\n",
      "20 (652, 360)\n",
      "21 (326, 216)\n",
      "22 (345, 198)\n",
      "23 (627, 360)\n",
      "24 (377, 309)\n",
      "27 (608, 360)\n",
      "30 (691, 360)\n",
      "31 (819, 356)\n",
      "32 (320, 183)\n",
      "33 (889, 244)\n",
      "34 (729, 356)\n",
      "35 (345, 266)\n",
      "39 (358, 230)\n",
      "42 (704, 363)\n",
      "43 (672, 360)\n",
      "44 (755, 360)\n",
      "45 (768, 363)\n",
      "50 (659, 360)\n",
      "51 (512, 360)\n",
      "54 (729, 363)\n",
      "55 (576, 298)\n",
      "56 (377, 241)\n",
      "57 (691, 363)\n",
      "58 (236, 327)\n",
      "59 (102, 147)\n",
      "60 (633, 284)\n",
      "61 (153, 68)\n",
      "64 (102, 68)\n",
      "65 (723, 342)\n",
      "66 (416, 306)\n",
      "67 (172, 108)\n",
      "68 (672, 370)\n",
      "69 (313, 219)\n",
      "70 (371, 244)\n",
      "75 (710, 61)\n",
      "78 (454, 356)\n",
      "79 (83, 147)\n",
      "80 (160, 144)\n",
      "83 (678, 363)\n",
      "84 (582, 345)\n",
      "89 (313, 108)\n",
      "92 (659, 356)\n",
      "97 (454, 277)\n",
      "98 (339, 201)\n",
      "99 (691, 345)\n",
      "102 (396, 216)\n",
      "103 (646, 342)\n",
      "104 (672, 360)\n",
      "105 (268, 125)\n",
      "106 (467, 226)\n",
      "107 (640, 428)\n",
      "116 (172, 86)\n",
      "119 (396, 251)\n",
      "120 (723, 356)\n",
      "121 (723, 356)\n",
      "122 (640, 403)\n",
      "123 (627, 360)\n",
      "124 (716, 356)\n",
      "127 (723, 352)\n",
      "128 (691, 349)\n",
      "129 (313, 244)\n",
      "130 (684, 356)\n",
      "131 (320, 288)\n",
      "132 (678, 345)\n",
      "133 (262, 172)\n",
      "134 (908, 457)\n",
      "135 (371, 234)\n",
      "136 (652, 338)\n",
      "137 (313, 367)\n",
      "138 (716, 356)\n",
      "139 (326, 212)\n",
      "140 (640, 82)\n",
      "141 (352, 216)\n",
      "142 (601, 356)\n",
      "143 (601, 259)\n",
      "146 (601, 108)\n",
      "147 (544, 356)\n",
      "150 (576, 302)\n",
      "151 (396, 205)\n",
      "152 (377, 144)\n",
      "153 (358, 223)\n",
      "154 (716, 360)\n",
      "155 (403, 147)\n",
      "158 (640, 367)\n",
      "159 (307, 154)\n",
      "166 (435, 86)\n",
      "169 (640, 349)\n",
      "176 (339, 169)\n",
      "177 (358, 172)\n",
      "182 (332, 172)\n",
      "183 (428, 118)\n",
      "184 (364, 187)\n",
      "189 (352, 284)\n",
      "190 (672, 360)\n",
      "191 (652, 374)\n",
      "192 (243, 183)\n",
      "195 (166, 75)\n",
      "196 (409, 165)\n",
      "197 (422, 122)\n",
      "200 (582, 284)\n",
      "201 (377, 165)\n",
      "202 (416, 133)\n",
      "203 (390, 198)\n",
      "204 (339, 216)\n",
      "205 (294, 208)\n",
      "206 (217, 140)\n",
      "207 (377, 270)\n",
      "208 (672, 61)\n",
      "209 (345, 158)\n",
      "210 (358, 176)\n",
      "211 (563, 363)\n",
      "214 (435, 273)\n",
      "215 (300, 248)\n",
      "216 (332, 205)\n",
      "217 (684, 352)\n",
      "218 (659, 363)\n",
      "221 (89, 97)\n",
      "222 (275, 72)\n",
      "223 (396, 198)\n",
      "226 (128, 248)\n",
      "227 (659, 378)\n",
      "228 (345, 270)\n",
      "231 (217, 183)\n",
      "232 (467, 90)\n",
      "233 (640, 370)\n",
      "234 (486, 122)\n",
      "240 (563, 291)\n",
      "241 (672, 327)\n",
      "242 (364, 251)\n",
      "243 (441, 144)\n",
      "244 (358, 241)\n",
      "245 (352, 198)\n",
      "246 (313, 251)\n",
      "247 (364, 176)\n",
      "250 (249, 208)\n",
      "251 (531, 248)\n",
      "252 (620, 349)\n",
      "253 (358, 172)\n",
      "256 (339, 194)\n",
      "266 (262, 194)\n",
      "267 (403, 230)\n",
      "268 (377, 212)\n",
      "269 (307, 75)\n",
      "272 (371, 169)\n",
      "273 (684, 360)\n",
      "274 (377, 154)\n",
      "277 (377, 273)\n",
      "278 (435, 237)\n",
      "279 (390, 180)\n",
      "280 (364, 194)\n",
      "281 (396, 198)\n",
      "282 (134, 169)\n",
      "283 (358, 172)\n",
      "284 (640, 356)\n",
      "285 (537, 356)\n",
      "286 (326, 97)\n",
      "289 (390, 158)\n",
      "290 (396, 194)\n",
      "293 (460, 208)\n",
      "294 (492, 212)\n",
      "300 (352, 180)\n",
      "301 (249, 201)\n",
      "304 (377, 162)\n",
      "307 (396, 248)\n",
      "308 (428, 151)\n",
      "313 (665, 360)\n",
      "314 (76, 54)\n",
      "321 (281, 259)\n",
      "322 (320, 180)\n",
      "323 (396, 255)\n",
      "324 (448, 262)\n",
      "325 (652, 57)\n",
      "326 (403, 158)\n",
      "329 (467, 169)\n",
      "332 (531, 104)\n",
      "335 (403, 165)\n",
      "338 (416, 216)\n",
      "343 (665, 352)\n",
      "344 (390, 136)\n",
      "345 (384, 183)\n",
      "346 (358, 187)\n",
      "347 (313, 262)\n",
      "348 (409, 162)\n",
      "349 (384, 176)\n",
      "350 (345, 208)\n",
      "351 (345, 212)\n",
      "352 (249, 183)\n",
      "353 (448, 165)\n",
      "354 (441, 255)\n",
      "357 (864, 172)\n",
      "364 (307, 237)\n",
      "365 (422, 176)\n",
      "370 (345, 313)\n",
      "371 (576, 309)\n",
      "372 (416, 226)\n",
      "373 (358, 205)\n",
      "374 (364, 223)\n",
      "375 (371, 154)\n",
      "376 (384, 205)\n",
      "377 (390, 190)\n",
      "378 (307, 244)\n",
      "383 (204, 108)\n",
      "394 (409, 169)\n",
      "399 (83, 54)\n",
      "407 (396, 176)\n",
      "411 (332, 172)\n",
      "412 (320, 223)\n",
      "415 (505, 104)\n",
      "416 (480, 327)\n",
      "417 (364, 176)\n",
      "422 (422, 251)\n",
      "427 (313, 223)\n",
      "428 (422, 205)\n",
      "431 (275, 288)\n",
      "439 (499, 284)\n",
      "440 (364, 219)\n",
      "444 (665, 370)\n",
      "445 (358, 187)\n",
      "446 (307, 190)\n",
      "447 (313, 262)\n",
      "450 (390, 216)\n",
      "455 (300, 280)\n",
      "456 (70, 54)\n",
      "457 (358, 270)\n",
      "462 (70, 57)\n",
      "463 (371, 201)\n",
      "466 (243, 79)\n",
      "471 (262, 248)\n",
      "472 (640, 363)\n",
      "473 (512, 288)\n",
      "474 (96, 57)\n",
      "478 (89, 57)\n",
      "482 (96, 54)\n",
      "485 (640, 360)\n",
      "486 (646, 356)\n",
      "487 (390, 212)\n",
      "490 (524, 360)\n",
      "491 (352, 190)\n",
      "492 (435, 183)\n",
      "493 (352, 266)\n",
      "496 (633, 288)\n",
      "497 (703, 338)\n",
      "502 (377, 234)\n",
      "503 (307, 219)\n",
      "504 (512, 295)\n",
      "507 (620, 266)\n",
      "513 (326, 241)\n",
      "514 (633, 334)\n",
      "517 (511, 219)\n",
      "518 (652, 349)\n",
      "519 (102, 295)\n",
      "522 (537, 255)\n",
      "525 (428, 244)\n",
      "526 (544, 273)\n",
      "531 (588, 262)\n",
      "532 (672, 342)\n",
      "533 (262, 270)\n",
      "534 (742, 345)\n",
      "535 (262, 266)\n",
      "538 (640, 363)\n",
      "539 (422, 352)\n",
      "544 (505, 266)\n",
      "549 (729, 360)\n",
      "550 (953, 396)\n",
      "551 (665, 270)\n",
      "552 (761, 338)\n",
      "553 (678, 356)\n",
      "554 (371, 194)\n",
      "557 (608, 136)\n",
      "558 (678, 334)\n",
      "559 (486, 125)\n",
      "560 (313, 158)\n",
      "565 (620, 320)\n",
      "566 (633, 331)\n",
      "567 (448, 169)\n",
      "568 (403, 280)\n",
      "571 (371, 226)\n",
      "572 (742, 360)\n",
      "573 (415, 244)\n",
      "574 (121, 68)\n",
      "579 (556, 342)\n",
      "586 (281, 64)\n",
      "587 (268, 248)\n",
      "588 (633, 100)\n",
      "589 (326, 255)\n",
      "590 (620, 367)\n",
      "593 (780, 360)\n",
      "594 (652, 363)\n",
      "597 (755, 313)\n",
      "604 (678, 338)\n",
      "605 (96, 72)\n",
      "606 (640, 262)\n",
      "607 (358, 169)\n",
      "608 (672, 313)\n",
      "612 (716, 360)\n",
      "613 (691, 349)\n",
      "618 (672, 352)\n",
      "619 (211, 223)\n",
      "620 (652, 356)\n",
      "624 (467, 259)\n",
      "625 (716, 345)\n",
      "626 (339, 183)\n",
      "629 (396, 262)\n",
      "632 (371, 144)\n",
      "633 (486, 237)\n",
      "637 (512, 230)\n",
      "638 (768, 140)\n",
      "642 (544, 342)\n",
      "643 (608, 313)\n",
      "644 (275, 108)\n",
      "645 (224, 363)\n",
      "646 (608, 334)\n",
      "650 (640, 363)\n",
      "658 (230, 489)\n",
      "661 (665, 302)\n",
      "662 (70, 57)\n",
      "663 (588, 57)\n",
      "666 (601, 316)\n",
      "667 (480, 266)\n",
      "668 (768, 356)\n",
      "669 (249, 241)\n",
      "672 (377, 176)\n",
      "679 (608, 266)\n",
      "684 (416, 223)\n",
      "691 (473, 248)\n",
      "692 (524, 313)\n",
      "693 (300, 262)\n",
      "694 (627, 338)\n",
      "697 (595, 219)\n",
      "702 (300, 370)\n",
      "707 (633, 316)\n",
      "708 (313, 205)\n",
      "713 (518, 97)\n",
      "714 (377, 295)\n",
      "715 (256, 72)\n",
      "718 (172, 395)\n",
      "719 (665, 367)\n",
      "720 (313, 345)\n",
      "721 (377, 284)\n",
      "725 (608, 309)\n",
      "726 (262, 284)\n",
      "727 (198, 187)\n",
      "732 (723, 356)\n",
      "735 (595, 309)\n",
      "738 (646, 342)\n",
      "739 (307, 370)\n",
      "740 (524, 334)\n",
      "741 (371, 208)\n",
      "742 (454, 219)\n",
      "745 (608, 313)\n",
      "746 (697, 316)\n",
      "751 (358, 262)\n",
      "752 (172, 291)\n",
      "755 (76, 165)\n",
      "756 (384, 410)\n",
      "760 (620, 352)\n",
      "761 (294, 219)\n",
      "762 (326, 79)\n",
      "767 (652, 338)\n",
      "768 (102, 54)\n",
      "769 (697, 370)\n",
      "770 (339, 352)\n",
      "786 (672, 403)\n",
      "787 (409, 356)\n",
      "788 (748, 360)\n",
      "791 (665, 360)\n",
      "792 (697, 356)\n",
      "797 (723, 115)\n",
      "798 (422, 302)\n",
      "799 (480, 360)\n",
      "802 (384, 291)\n",
      "803 (659, 406)\n",
      "806 (486, 162)\n",
      "809 (640, 360)\n",
      "812 (640, 363)\n",
      "815 (307, 230)\n",
      "816 (236, 176)\n",
      "817 (550, 360)\n",
      "818 (358, 284)\n",
      "819 (633, 356)\n",
      "822 (512, 360)\n",
      "825 (505, 273)\n",
      "828 (505, 118)\n",
      "829 (217, 122)\n",
      "830 (761, 374)\n",
      "831 (556, 360)\n",
      "834 (633, 342)\n",
      "837 (441, 360)\n",
      "838 (608, 133)\n",
      "839 (569, 349)\n",
      "842 (582, 280)\n",
      "843 (505, 140)\n",
      "844 (256, 320)\n",
      "845 (256, 205)\n",
      "848 (473, 251)\n",
      "851 (646, 356)\n",
      "852 (736, 363)\n",
      "853 (358, 270)\n",
      "854 (217, 223)\n",
      "855 (512, 324)\n",
      "856 (352, 90)\n",
      "857 (262, 234)\n",
      "858 (256, 205)\n",
      "861 (480, 360)\n",
      "864 (390, 349)\n",
      "865 (224, 111)\n",
      "866 (300, 183)\n",
      "867 (211, 136)\n",
      "868 (224, 205)\n",
      "869 (595, 360)\n",
      "225\n",
      "227\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "### draw points on top of image for display\n",
    "\n",
    "def draw_markers(df, ratio):\n",
    "    '''draw markers on image'''\n",
    "    file = 'entry_gate_empty_frame.png'\n",
    "    image = cv2.imread(file)\n",
    "    print(image.shape)\n",
    "    h, w, v = image.shape\n",
    "    for ind, row in df.iterrows():\n",
    "        point = (int(row['box_x_center']*w), int(row['box_y_center']*h))\n",
    "        #point = (int(row['yolo_x_max']), int(row['yolo_y_max']))\n",
    "        print(ind, point)\n",
    "        if row['plate_present'] == 1:\n",
    "            color = (0, 0, 255)\n",
    "        elif row['plate_present'] == 0:\n",
    "            color = (255, 0, 0)\n",
    "        cv2.circle(image, point, radius=5, color=color, thickness=-1)\n",
    "    image = cv2.resize(image, (0, 0), None, ratio, ratio)\n",
    "    cv2.imshow('Box Center', image)\n",
    "    while True:\n",
    "        k = cv2.waitKey(0) & 0xFF\n",
    "        print(k)\n",
    "        if k == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "#print(df.loc[df['plate_present'] == 1]['plate_present', 'box_x_center'])\n",
    "draw_markers(df, ratio=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f767b7375f5949278cda0b96a049f156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': array([0., 0., 1., ..., 0., 0., 0.])},\n",
       "              'mode': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.FigureWidget(layout={'hovermode': 'closest', \"title_text\":\"overlapping area width vs height\"})\n",
    "#_ = fig.add_scatter(x=df['box_height_over_width'], y=df['plate_present'], mode='markers', marker={\"color\":df['plate_present']})\n",
    "_ = fig.add_scatter(x=(df['over_x_max'] - df['over_x_min']),y=(df['over_y_max']-df['over_y_min']), mode='markers', marker={\"color\":df['plate_present']})\n",
    "scatter = fig.data[0]\n",
    "scatter.on_click(do_click)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e456a1395c49b2ad9719bede4a74d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': array([0., 0., 1., ..., 0., 0., 0.])},\n",
       "              'mode': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.FigureWidget(layout={'hovermode': 'closest', \"title_text\":\"overlapping x's max coordinates and y_max - y_min\"})\n",
    "#_ = fig.add_scatter(x=df['box_height_over_width'], y=df['plate_present'], mode='markers', marker={\"color\":df['plate_present']})\n",
    "_ = fig.add_scatter(x=df['over_x_max'],y=(df['over_y_max'] - df['over_y_min']), mode='markers', marker={\"color\":df['plate_present']})\n",
    "scatter = fig.data[0]\n",
    "scatter.on_click(do_click)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314    0.0\n",
      "399    0.0\n",
      "456    0.0\n",
      "462    0.0\n",
      "482    0.0\n",
      "662    0.0\n",
      "Name: plate_present, dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e99a70eb86c47fea53b2265a651a11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': array([0., 0., 0., 0., 0., 0.])},\n",
       "              'mode': 'mark…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# overlap area == 0\n",
    "\n",
    "zero_overlap = df[df['overlap_area'] == 0]\n",
    "print(zero_overlap.plate_present)\n",
    "fig = go.FigureWidget(layout={'hovermode': 'closest', \"title_text\":\"zero overlap boxarea vs plate_present\"})\n",
    "_ = fig.add_scatter(x=zero_overlap['box_area'],y=zero_overlap['plate_present'], mode='markers', marker={\"color\":zero_overlap['plate_present']})\n",
    "scatter = fig.data[0]\n",
    "scatter.on_click(do_click)\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['物体画像', 'ナンバープレート', 'box_x_min', 'box_y_min', 'box_x_max', 'box_y_max',\n",
      "       'over_x_min', 'over_y_min', 'over_x_max', 'over_y_max', 'aoi_x_min',\n",
      "       'aoi_y_min', 'aoi_x_max', 'aoi_y_max', 'box_height', 'box_width',\n",
      "       'img_url', 'box_area', 'overlap_area', 'area_of_interest',\n",
      "       'box_height_over_width', 'frame_area', 'plate_present', 'box_x_center',\n",
      "       'box_y_center', 'link'],\n",
      "      dtype='object')\n",
      "Index(['物体画像', 'ナンバープレート', 'box_x_min', 'box_y_min', 'box_x_max', 'box_y_max',\n",
      "       'over_x_min', 'over_y_min', 'over_x_max', 'over_y_max', 'aoi_x_min',\n",
      "       'aoi_y_min', 'aoi_x_max', 'aoi_y_max', 'box_height', 'box_width',\n",
      "       'img_url', 'box_area', 'overlap_area', 'area_of_interest',\n",
      "       'box_height_over_width', 'frame_area', 'plate_present', 'box_x_center',\n",
      "       'box_y_center', 'link'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc1da8f3f824321b2999b6bda24106b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'hovertext': array([], dtype=object),\n",
       "              'mode': 'markers',\n",
       "          …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zo_ = zero_overlap[zero_overlap['plate_present'] == 1]\n",
    "ov = df[(df['overlap_area'] > 0) & (df['plate_present'] == 1)]\n",
    "zo_['link'] = zo_['img_url'].map(lambda x: to_link(x))\n",
    "ov['link'] = ov['img_url'].map(lambda x: to_link(x))\n",
    "print(ov.columns)\n",
    "print(zo_.columns)\n",
    "fig = go.FigureWidget(layout={'hovermode': 'closest', \"title_text\":\"zero overlap boxarea vs plate_present\"})\n",
    "_ = fig.add_scatter(x=zo_['box_x_center'],y=zo_['box_y_center'], mode='markers', hovertext=zo_['link'])\n",
    "_ = fig.add_scatter(x=ov['box_x_center'],y=ov['box_y_center'], mode='markers', hovertext=ov['link'])\n",
    "scatter = fig.data[0]\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: 0.7125890736342043\n",
      "confusion matrix:\n",
      " [[127  84]\n",
      " [ 37 173]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf = LogisticRegression(random_state=0)\n",
    "\n",
    "x = df[['box_height', 'box_width']]  # 0.5694\n",
    "\n",
    "x = df[['box_x_center', 'box_y_center']] # 0.5763097949886105\n",
    "\n",
    "df['over_width'] = df['over_x_max'] - df['over_x_min']\n",
    "df['over_height'] = df['over_y_max'] - df['over_y_min']\n",
    "x = df[['over_width', 'over_height']] # 0.5854214123006833\n",
    "\n",
    "\n",
    "x = df[['box_height', 'box_width', 'box_x_center', 'box_y_center', 'over_width', 'over_height']] # 0.642369020501139\n",
    "y = df['plate_present']\n",
    "clf.fit(x,y)\n",
    "\n",
    "print(\"training set score:\", clf.score(x, y))\n",
    "cm = confusion_matrix(y, clf.predict(x))\n",
    "print(\"confusion matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying ML to the selected feature ##\n",
    "\n",
    "### Resources\n",
    "* [reduce false negative and increase recall for SVM](https://stats.stackexchange.com/questions/277347/optimise-svm-to-avoid-false-negative-in-binary-classification)\n",
    "* [plot decision boundary](https://scikit-learn.org/0.18/auto_examples/svm/plot_iris.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: 0.9052631578947369\n",
      "confusion matrix:\n",
      " [[192  93]\n",
      " [  8 467]]\n",
      "precision: 0.8339285714285715\n",
      "recall: 0.9831578947368421\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def clf_predict(x, threshold):\n",
    "    '''\n",
    "    given x and threshold probability, return prediction\n",
    "    '''\n",
    "    pred = clf.predict_proba(x)[:,1]\n",
    "    pred[pred < threshold] = 0\n",
    "    pred[pred >= threshold] = 1\n",
    "    return pred\n",
    "\n",
    "clf = SVC(probability=True)\n",
    "x = df[[ 'box_x_min', 'box_y_min', 'box_x_max', 'box_y_max',\\\n",
    "       'over_x_min', 'over_y_min', 'over_x_max', 'over_y_max', 'aoi_x_min',\\\n",
    "       'aoi_y_min', 'aoi_x_max', 'aoi_y_max', 'box_height', 'box_width']]  \n",
    "\n",
    "feature_names = ['box_height', 'box_width', 'box_x_center', 'box_y_center']\n",
    "x = df[['box_height', 'box_width', 'box_x_center', 'box_y_center']].values\n",
    "\n",
    "#x = x[:,:2]\n",
    "#y = df['plate_present']\n",
    "y = df['gate_incoming'].values\n",
    "clf.fit(x,y)\n",
    "\n",
    "#pred = clf.predict(x)\n",
    "pred = clf_predict(x, threshold=0.165489)\n",
    "print(\"training set score:\", clf.score(x, y))\n",
    "cm = confusion_matrix(y, pred)\n",
    "print(\"confusion matrix:\\n\", cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "\n",
    "recall = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "precision = cm[1][1]/(cm[0][1]+cm[1][1])\n",
    "\n",
    "print(\"precision: {precision}\\nrecall: {recall}\".format(precision=precision, recall=recall))\n",
    "#print(clf.predict_proba(x).min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(98, 96) (98, 96)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 2 should be equal to 4, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-e625387e5b92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_meshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mplot_contours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoolwarm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoolwarm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"k\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-156-e625387e5b92>\u001b[0m in \u001b[0;36mplot_contours\u001b[0;34m(ax, clf, xx, yy, **params)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_contours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.165489\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-155-c79ecec50819>\u001b[0m in \u001b[0;36mclf_predict\u001b[0;34m(x, threshold)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mgiven\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     '''\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/opencv_motion_detection/motion_env/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             raise NotFittedError(\"predict_proba is not available when fitted \"\n",
      "\u001b[0;32m~/Projects/opencv_motion_detection/motion_env/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    491\u001b[0m                                  (X.shape[1], self.shape_fit_[0]))\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_fit_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[0m\u001b[1;32m    494\u001b[0m                              \u001b[0;34m\"the number of features at training time\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                              (X.shape[1], self.shape_fit_[1]))\n",
      "\u001b[0;31mValueError\u001b[0m: X.shape[1] = 2 should be equal to 4, the number of features at training time"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - .5, x.max() + .5\n",
    "    y_min, y_max = y.min() - .5, y.max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    Z = clf_predict(np.c_[xx.ravel(), yy.ravel()], 0.165489)\n",
    "    #Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    #Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "# title for the plots\n",
    "title = ('Decision surface of linear SVC')\n",
    "# Set-up grid for plotting.\n",
    "print(type(x))\n",
    "X0, X1 = x[:, 0], x[:, 1]\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "print(xx.shape, yy.shape)\n",
    "plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
    "ax.set_ylabel(\"{}\".format(feature_names[0]))\n",
    "ax.set_xlabel(\"{}\".format(feature_names[1]))\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Unnamed: 0.1', 'カメラID', '物体画像', '処理開始時間', 'ナンバープレート',\n",
      "       'N地域名', 'N分類番号', 'N平仮名等', 'N一連指定番号', 'タイムスタンプ', '物体詳細', 'box_x_min',\n",
      "       'box_y_min', 'box_x_max', 'box_y_max', 'over_x_min', 'over_y_min',\n",
      "       'over_x_max', 'over_y_max', 'aoi_x_min', 'aoi_y_min', 'aoi_x_max',\n",
      "       'aoi_y_max', 'box_height', 'box_width', 'img_url', 'gate_incoming',\n",
      "       'box_area', 'overlap_area', 'area_of_interest', 'box_height_over_width',\n",
      "       'frame_area', 'plate_present', 'box_x_center', 'box_y_center',\n",
      "       'local_img_path', 'motion_score', 'blur_score', 'gate_plate',\n",
      "       'yolo_x_min', 'yolo_x_max', 'yolo_y_min', 'yolo_y_max', 'yolo_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rf = df\n",
    "print(rf.columns)\n",
    "rf['pred'] = clf_predict(x, threshold=0.165489)\n",
    "rf['y'] = y\n",
    "\n",
    "rf['label'] = 1\n",
    "rf.loc[(rf['pred'] == 1) & (rf['y'] == 0), 'label'] = 2\n",
    "rf.loc[(rf['pred'] == 0) & (rf['y'] == 1), 'label'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 48)\n",
      "49\n",
      "96\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# image display with cv2\n",
    "FN = rf[rf['label'] == 3]\n",
    "FP = rf[rf['label'] == 2]\n",
    "print(FN.shape)\n",
    "tile_image(FP.reset_index(drop=True), cols=3, rows=3, shrink=0.5, draw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f19c309fe894eaaa7d2c2ed1f48172a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.FigureWidget(layout={'hovermode': 'closest', \"title_text\":\"overlapping x's max coordinates and y_max - y_min\"})\n",
    "data = rf[rf['label'] == 2]\n",
    "#_ = fig.add_scatter(x=df['box_height_over_width'], y=df['plate_present'], mode='markers', marker={\"color\":df['plate_present']})\n",
    "_ = fig.add_scatter(x=data['box_x_center'],y=(data['box_y_center']), mode='markers', marker={\"color\":data['label']})\n",
    "\n",
    "def do_click(trace, points, state):\n",
    "    if points.point_inds:\n",
    "        ind = points.point_inds[0]\n",
    "        url = data[\"img_url\"].iloc[ind]\n",
    "        webbrowser.open_new_tab(url) \n",
    "\n",
    "scatter = fig.data[0]\n",
    "scatter.on_click(do_click)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings - False Positive\n",
    "False Positives can be classified into the followings.\n",
    "\n",
    "1. vehicles that are located on far left side, and has nothing to do with gate\n",
    "    * these have lower box_x_center and overlap_area values. Example imgs are below with one execption.\n",
    "\n",
    "        * <img src=\"https://orix-demo.s3.amazonaws.com/image-processor-result/frames/2021/2/17/0/entry_2021-02-12_10-00-30.mp4/camera_stored-video_car_2.jpg?AWSAccessKeyId=AKIAQFFHM4W7DIPSXUEV&Signature=DJCu14lZTRj48sgumz1NAdHGfIA%3D&Expires=1615939172\">\n",
    "        * <img src=\"https://orix-demo.s3.amazonaws.com/image-processor-result/frames/2021/2/17/0/entry_2021-02-12_10-00-30.mp4/camera_stored-video_car_11.jpg?AWSAccessKeyId=AKIAQFFHM4W7DIPSXUEV&Signature=sXqvXRRDRUOHQChFwbNJT%2BVMLe4%3D&Expires=1615939192\">\n",
    "        * <img src=\"https://orix-demo.s3.amazonaws.com/image-processor-result/frames/2021/2/17/1/entry_2021-02-12_10-00-30.mp4/camera_stored-video_car_80.jpg?AWSAccessKeyId=AKIAQFFHM4W7DIPSXUEV&Signature=AQvyX0%2FkvpIuFEIRS3bTyG9GWvc%3D&Expires=1615939344\">\n",
    "        \n",
    "        * **Exception** <br>\n",
    "        <img src=\"https://orix-demo.s3.amazonaws.com/image-processor-result/frames/2021/2/17/2/entry_2021-02-16_09-01-00.mp4/camera_stored-video_car_257.jpg?AWSAccessKeyId=AKIAQFFHM4W7DIPSXUEV&Signature=CpbwFlaF9Xdc5WOlvIISNhTivbM%3D&Expires=1615945765\">\n",
    "        \n",
    "    \n",
    "2. Vehicles that are going into the gate  \n",
    "    a. ones that are angled and not facing straight at camera\n",
    "        a. **Too shallow angle**  \n",
    "        <img src=\"https://orix-demo.s3.amazonaws.com/image-processor-result/frames/2021/2/17/1/entry_2021-02-12_10-00-30.mp4/camera_stored-video_car_51.jpg?AWSAccessKeyId=AKIAQFFHM4W7DIPSXUEV&Signature=%2B8QCxgrg15wM41ncLe3G17gpVAw%3D&Expires=1615939281\">  \n",
    "        b. **Too deep angle**  \n",
    "        <img src=\"https://orix-demo.s3.amazonaws.com/image-processor-result/frames/2021/2/17/2/entry_2021-02-16_09-01-00.mp4/camera_stored-video_car_65.jpg?AWSAccessKeyId=AKIAQFFHM4W7DIPSXUEV&Signature=bVxOY4vUqjGdbFNlj41JkgMkLxI%3D&Expires=1615945345\">  \n",
    "    b. ones that are facing straight at camera, but plate is not detected (lighting??)  \n",
    "        a. <img src=\"https://orix-demo.s3.amazonaws.com/image-processor-result/frames/2021/2/17/2/entry_2021-02-16_09-01-00.mp4/camera_stored-video_car_60.jpg?AWSAccessKeyId=AKIAQFFHM4W7DIPSXUEV&Signature=Oz6t6F8zmaQR9VJGvdTwxsqxrIc%3D&Expires=1615945335\">\n",
    "        b. <img src=\"https://orix-demo.s3.amazonaws.com/image-processor-result/frames/2021/2/17/2/entry_2021-02-16_09-01-00.mp4/camera_stored-video_car_147.jpg?AWSAccessKeyId=AKIAQFFHM4W7DIPSXUEV&Signature=Vb0sMjG7M4Fz2%2FKN3u4EyJqwdUc%3D&Expires=1615945524\">\n",
    "\n",
    "* **Rule Driven from above**\n",
    "    1. exclude if `box_x_center` < 0.2\n",
    "    2. include if `box_x_center` > 0.25\n",
    "    3. if 0.2 < `box_x_center` < 0.25  \n",
    "        * evaluate  box's height vs width ratio.<br>\n",
    "\n",
    "2 and 3 needs to be further refined, as 2 might include vehicles going out, as well as ones facing cameras on its side. 3 might include gate vehicles with larger turning radius.\n",
    "\n",
    "Vehicles on class 1 can be filtered by creating threshold on box's center x coordinate.\n",
    "\n",
    "Let's further analyze in order to refine rules 2 and 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e8cbbfa39941708984c908eaaded05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "two_data = data[data['box_x_center'] > 0.25]\n",
    "\n",
    "fig = go.FigureWidget(layout={'hovermode': 'closest', \"title_text\":\"box's width vs height\"})\n",
    "#_ = fig.add_scatter(x=df['box_height_over_width'], y=df['plate_present'], mode='markers', marker={\"color\":df['plate_present']})\n",
    "_ = fig.add_scatter(x=(two_data['box_height']/two_data['box_width']),y=(two_data['box_y_center']), mode='markers', marker={\"color\":two_data['label']})\n",
    "\n",
    "def do_click(trace, points, state):\n",
    "    if points.point_inds:\n",
    "        ind = points.point_inds[0]\n",
    "        url = two_data[\"img_url\"].iloc[ind]\n",
    "        webbrowser.open_new_tab(url) \n",
    "\n",
    "scatter = fig.data[0]\n",
    "scatter.on_click(do_click)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph analysis for rule2 refinment.\n",
    "* left buttom corner's cluster  \n",
    "vehicles waiting on the road to get in (located on top half of frame)\n",
    "* middle cluster is almost all ideal angle and location of vehicles in frame (Note the exceptions below)\n",
    "* top right corner's cluster tends to include smaller sized vehicles with deeper camera angle\n",
    "\n",
    "**Exceptions of vehicles sticking out at the left side of frame**  \n",
    "`box_x_min` <= 0  \n",
    "In this case, license plate is also almost at the edge of the frame\n",
    "\n",
    "\n",
    "**From above insights, rule 2 can be further refined by folllwings.**  \n",
    "1. include if `box_height/box_width` >= 1.1  and excludeones with `box_x_min` <= 0 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69     0.245\n",
      "133    0.205\n",
      "159    0.240\n",
      "266    0.205\n",
      "378    0.240\n",
      "761    0.230\n",
      "815    0.240\n",
      "857    0.205\n",
      "866    0.235\n",
      "Name: box_x_center, dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2035fc61614eaf8bca09a78225e1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': array([2, 2, 2, 2, 2, 2, 2, 2, 2])},\n",
       "              'mode': 'm…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "three_data = data[(data['box_x_center'] > 0.2) & (data['box_x_center'] < 0.25)]\n",
    "print(three_data.box_x_center)\n",
    "fig = go.FigureWidget(layout={'hovermode': 'closest', \"title_text\":\"box's width vs height\"})\n",
    "#_ = fig.add_scatter(x=df['box_height_over_width'], y=df['plate_present'], mode='markers', marker={\"color\":df['plate_present']})\n",
    "_ = fig.add_scatter(x=three_data['box_height'], y=three_data['box_width'], mode='markers', marker={\"color\":three_data['label']})\n",
    "\n",
    "def do_click(trace, points, state):\n",
    "    if points.point_inds:\n",
    "        ind = points.point_inds[0]\n",
    "        url = three_data[\"img_url\"].iloc[ind]\n",
    "        webbrowser.open_new_tab(url) \n",
    "\n",
    "scatter = fig.data[0]\n",
    "scatter.on_click(do_click)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Analysis for rule3 refinment.\n",
    "All of the points above contain unrelevant vehicles on the street, except the right upper corner points. Picture is below.\n",
    "\n",
    "<img src=\"https://orix-demo.s3.amazonaws.com/image-processor-result/frames/2021/2/17/2/entry_2021-02-16_09-01-00.mp4/camera_stored-video_car_257.jpg?AWSAccessKeyId=AKIAQFFHM4W7DIPSXUEV&Signature=CpbwFlaF9Xdc5WOlvIISNhTivbM%3D&Expires=1615945765\">\n",
    "\n",
    "**Because this is the outlier, we will ignore at this moment.**\n",
    "\n",
    "\n",
    "### Applying the Rules to False Positives\n",
    "\n",
    "Final rule drived from above analysis of False Positive cases are below in order.\n",
    "\n",
    "```python\n",
    "\n",
    "if `box_x_center` < 0.25: # ignoring rule 3 for now\n",
    "    predict 0 (no plate present)\n",
    "else:\n",
    "    if `box_height/box_width` > 1.1:\n",
    "        if `box_x_min` < 0:\n",
    "            predict 0\n",
    "        else:\n",
    "            predict 1\n",
    "    else:\n",
    "        predict 0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 30)\n",
      "(17, 30)\n",
      "(31, 30)\n",
      "(31, 30)\n",
      "# of False Positives after rule application:      box_x_center  pred  plate_present\n",
      "15          0.440   1.0            0.0\n",
      "60          0.495   1.0            0.0\n",
      "143         0.470   1.0            0.0\n",
      "150         0.450   1.0            0.0\n",
      "200         0.455   1.0            0.0\n",
      "211         0.440   1.0            0.0\n",
      "214         0.340   1.0            0.0\n",
      "228         0.270   1.0            0.0\n",
      "267         0.315   1.0            0.0\n",
      "307         0.310   1.0            0.0\n",
      "422         0.330   1.0            0.0\n",
      "440         0.285   1.0            0.0\n",
      "544         0.395   1.0            0.0\n",
      "567         0.350   1.0            0.0\n",
      "661         0.520   1.0            0.0\n",
      "667         0.375   1.0            0.0\n",
      "684         0.325   1.0            0.0\n",
      "825         0.395   1.0            0.0\n",
      "848         0.370   1.0            0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075fde01161c467f99757abfff806d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now applying the generated rules to the FP result of SVC\n",
    "FP = rf[rf['label']==2]\n",
    "print(FP[FP['pred']==0].shape)\n",
    "FP.loc[FP['box_x_center'] < 0.25, 'pred'] = 0\n",
    "print(FP[FP['pred']==0].shape)\n",
    "FP.loc[(FP['box_x_center'] >= 0.25) & (FP['box_height_over_width'] < 1.1), 'pred'] = 0\n",
    "FP.loc[(FP['box_x_center'] >= 0.25) & (FP['box_height_over_width'] > 1.1) & (FP['box_x_min'] <= 0), 'pred'] = 0\n",
    "print(FP[FP['pred']==0].shape)\n",
    "FP.loc[(FP['box_x_center'] >= 0.25) & (FP['box_height_over_width'] > 1.1) & (FP['box_x_min'] > 0), 'pred'] = 1\n",
    "print(FP[FP['pred']==0].shape)\n",
    "\n",
    "FP_result = FP[(FP['pred'] == 1) & (FP['plate_present'] == 0)]\n",
    "print(\"# of False Positives after rule application:\", FP_result[['box_x_center', 'pred', 'plate_present']])\n",
    "\n",
    "fig = go.FigureWidget(layout={'hovermode': 'closest', \"title_text\":\"box's width vs height\"})\n",
    "#_ = fig.add_scatter(x=df['box_height_over_width'], y=df['plate_present'], mode='markers', marker={\"color\":df['plate_present']})\n",
    "_ = fig.add_scatter(x=(FP_result['box_height']/FP_result['box_width']),y=(FP_result['box_x_min']), mode='markers', marker={\"color\":FP_result['label']})\n",
    "\n",
    "def do_click(trace, points, state):\n",
    "    if points.point_inds:\n",
    "        ind = points.point_inds[0]\n",
    "        url = FP_result[\"img_url\"].iloc[ind]\n",
    "        webbrowser.open_new_tab(url) \n",
    "\n",
    "scatter = fig.data[0]\n",
    "scatter.on_click(do_click)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successfully reduced # of FP from 50 -> 31, whose frames contains fairly visible license plates of incoming vehicles. Lighting of the photos or other factors that cannot be inferred from given features might be causing this. \n",
    "\n",
    "### False Negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d718936bafa4f77a54c86a23462f674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'marker': {'color': array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.FigureWidget(layout={'hovermode': 'closest', \"title_text\":\"overlapping x's max coordinates and y_max - y_min\"})\n",
    "data = rf[rf['label'] == 3]\n",
    "#_ = fig.add_scatter(x=df['box_height_over_width'], y=df['plate_present'], mode='markers', marker={\"color\":df['plate_present']})\n",
    "_ = fig.add_scatter(x=data['box_x_min'],y=(1-data['box_x_max']), mode='markers', marker={\"color\":data['label']})\n",
    "def do_click(trace, points, state):\n",
    "    if points.point_inds:\n",
    "        ind = points.point_inds[0]\n",
    "        url = data[\"img_url\"].iloc[ind]\n",
    "        webbrowser.open_new_tab(url) \n",
    "\n",
    "scatter = fig.data[0]\n",
    "scatter.on_click(do_click)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set score: 0.5537190082644629\n",
      "[1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0.\n",
      " 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1.]\n",
      "confusion matrix:\n",
      " [[44 47]\n",
      " [ 7 23]]\n",
      "precision: 0.32857142857142857\n",
      "recall: 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_features=\"\")\n",
    "x = df[[ 'box_x_min', 'box_y_min', 'box_x_max', 'box_y_max',\\\n",
    "       'over_x_min', 'over_y_min', 'over_x_max', 'over_y_max', 'aoi_x_min',\\\n",
    "       'aoi_y_min', 'aoi_x_max', 'aoi_y_max', 'box_height', 'box_width']]  \n",
    "x = df[['box_height', 'box_width', 'box_x_center', 'box_y_center', 'over_width', 'over_height']]\n",
    "\n",
    "y = df['plate_present']\n",
    "\n",
    "x_train = x.iloc[:300, :]\n",
    "y_train = y.iloc[:300]\n",
    "\n",
    "x_test = x.iloc[300:, :]\n",
    "y_test = y.iloc[300:]\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(\"test set score:\", clf.score(x_test, y_test))\n",
    "cm = confusion_matrix(y_test, clf.predict(x_test))\n",
    "print(clf.predict(x_test))\n",
    "print(\"confusion matrix:\\n\", cm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "#disp.plot()\n",
    "\n",
    "recall = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "precision = cm[1][1]/(cm[0][1]+cm[1][1])\n",
    "print(\"precision: {precision}\\nrecall: {recall}\".format(precision=precision, recall=recall))\n",
    "\n",
    "#tree.plot_tree(clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motion_env",
   "language": "python",
   "name": "motion_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
